# Test Design: Story 4.4 - Engagement-Based Smart Selection

**Date:** 2025-11-03
**Designer:** Quinn (Test Architect)
**Story:** 4.4 - Engagement-Based Smart Selection
**Epic:** 4 - Time Limits & Enhancements

---

## Test Strategy Overview

**Total Test Scenarios:** 43
**Distribution:**
- Unit Tests: 22 (51%)
- Integration Tests: 15 (35%)
- E2E Tests: 6 (14%)

**Priority Distribution:**
- P0 (Critical): 25 tests (58%)
- P1 (High): 12 tests (28%)
- P2 (Medium): 6 tests (14%)

**Coverage Focus:**
- TIER 1 Safety Rules: 100% coverage (9 tests)
- Core Algorithm Logic: Comprehensive unit + integration (18 tests)
- Edge Cases: All scenarios covered (8 tests)
- Admin Features: Happy path + key errors (6 tests)
- Performance: Benchmarks per Task 11 (4 tests)

---

## Test Scenarios by Acceptance Criteria

### AC1: Engagement score calculated per video (completion rate, replay frequency)

**Test Strategy:** Unit tests for calculation logic, integration tests for database interaction, performance benchmarks for large datasets.

| ID | Level | Priority | Test Scenario | Justification |
|----|-------|----------|---------------|---------------|
| 4.4-UNIT-001 | Unit | P0 | Calculate completion rate: 3 completed / 5 total = 0.6 | Pure calculation logic, must be accurate for engagement scoring |
| 4.4-UNIT-002 | Unit | P0 | Calculate replay frequency using unique watch days | Logarithmic scaling for replay weight, core algorithm component |
| 4.4-UNIT-003 | Unit | P0 | Calculate base engagement: completion_rate × log(1 + unique_days) | Formula correctness critical for weighted selection |
| 4.4-UNIT-004 | Unit | P1 | Handle zero watches (new video): return baseline weight 0.5 | Edge case: videos with no history must appear |
| 4.4-INT-001 | Integration | P0 | Query watch_history excluding manual_play=1 (TIER 1 Rule 2) | TIER 1 Safety: manual plays must not affect engagement |
| 4.4-INT-002 | Integration | P0 | Query watch_history excluding grace_play=1 (TIER 1 Rule 2) | TIER 1 Safety: grace plays must not affect engagement |
| 4.4-INT-003 | Integration | P1 | Calculate engagement scores for 9 videos from database | Integration: service + database, typical grid load scenario |
| 4.4-PERF-001 | Integration | P2 | Benchmark engagement calculation with 100 videos, 10K watch history | Performance target: <500ms per Task 11 requirement |

**Coverage Summary:** 8 tests (5 unit, 3 integration, 1 performance) - Comprehensive coverage of calculation logic with TIER 1 safety focus.

---

### AC2: Videos weighted by engagement: high engagement = higher selection probability

**Test Strategy:** Unit tests for weighting algorithm, integration tests for statistical verification of selection behavior.

| ID | Level | Priority | Test Scenario | Justification |
|----|-------|----------|---------------|---------------|
| 4.4-UNIT-005 | Unit | P0 | Apply engagement weight to video selection probability | Core weighting algorithm logic |
| 4.4-UNIT-006 | Unit | P1 | Normalize weights for random.choices() input | Ensures proper probability distribution |
| 4.4-INT-004 | Integration | P0 | Run selection 100 times: high-engagement videos appear >60% of time | Statistical validation of weighted selection working as designed |
| 4.4-INT-005 | Integration | P1 | Low-engagement videos still appear but less frequently | Ensures fairness: no videos completely excluded |
| 4.4-E2E-001 | E2E | P1 | Child sees varied grid with mix of high/low engagement videos | User experience: variety perception validated |

**Coverage Summary:** 5 tests (2 unit, 2 integration, 1 E2E) - Validates core weighted selection behavior statistically.

---

### AC3: Recently watched videos (last 24h) have lower weight (encourage variety)

**Test Strategy:** Unit tests for recency decay function, integration tests with real timestamps and UTC time validation.

| ID | Level | Priority | Test Scenario | Justification |
|----|-------|----------|---------------|---------------|
| 4.4-UNIT-007 | Unit | P1 | Apply 24h recency penalty: weight × 0.3 (70% reduction) | Decay function correctness for recent watches |
| 4.4-UNIT-008 | Unit | P1 | Apply 24h-7d recency penalty: weight × 0.7 (30% reduction) | Medium-term decay function |
| 4.4-UNIT-009 | Unit | P1 | No penalty for watches >7 days old: weight × 1.0 | Old watches don't affect current selection |
| 4.4-INT-006 | Integration | P0 | Verify UTC time used for 24h recency calculation (TIER 1 Rule 3) | TIER 1 Safety: prevents timezone bugs in limit calculations |
| 4.4-INT-007 | Integration | P1 | Videos watched 2 hours ago have lower selection rate than unwatched | Real-world timestamp handling, variety enforcement |
| 4.4-INT-008 | Integration | P1 | Mock current time at different timezones, verify UTC consistency | Edge case: timezone transitions don't break recency |

**Coverage Summary:** 6 tests (3 unit, 3 integration) - Comprehensive recency decay with TIER 1 UTC time focus.

---

### AC4: Never completely hide videos (always small chance of selection)

**Test Strategy:** Unit tests for minimum weight floor, integration tests to verify floor applied in all scenarios including edge cases.

| ID | Level | Priority | Test Scenario | Justification |
|----|-------|----------|---------------|---------------|
| 4.4-UNIT-010 | Unit | P0 | Apply minimum weight floor: max(calculated_weight, 0.05) | Safety: ensures all videos selectable, prevents empty grids |
| 4.4-UNIT-011 | Unit | P0 | Video with 0.01 calculated weight adjusted to 0.05 | Floor enforcement for very low engagement |
| 4.4-INT-009 | Integration | P0 | All videos in selection pool have weight ≥ 0.05 | Integration validation: floor applied after all calculations |
| 4.4-INT-010 | Integration | P0 | Videos with zero engagement have 0.05 weight minimum | Edge case: brand new videos still appear |

**Coverage Summary:** 4 tests (2 unit, 2 integration) - P0 safety-critical: ensures variety and prevents empty grids.

---

### AC5: Parent can reset engagement data via admin interface

**Test Strategy:** Integration tests for endpoint behavior, E2E tests for complete admin workflow.

| ID | Level | Priority | Test Scenario | Justification |
|----|-------|----------|---------------|---------------|
| 4.4-INT-011 | Integration | P2 | POST /admin/engagement/reset deletes all engagement data | Admin endpoint functionality |
| 4.4-INT-012 | Integration | P2 | Reset single video: DELETE watch_history WHERE video_id AND manual_play=0 AND grace_play=0 | Selective reset preserves manual/grace history |
| 4.4-INT-013 | Integration | P2 | Verify SQL placeholders used (TIER 1 Rule 6) | TIER 1 Safety: SQL injection prevention |
| 4.4-INT-014 | Integration | P0 | Reset endpoint requires authentication (TIER 2 Rule 10) | Security: prevent unauthorized engagement manipulation |
| 4.4-E2E-002 | E2E | P2 | Admin clicks reset button, confirms dialog, sees success message | Complete admin workflow validation |
| 4.4-E2E-003 | E2E | P2 | After reset, child sees equal variety (no engagement bias) | User impact: reset effectiveness verified |

**Coverage Summary:** 6 tests (4 integration, 2 E2E) - Admin feature with security focus.

---

### AC6: Selection algorithm balances novelty and familiar favorites

**Test Strategy:** Integration tests to verify balance between new videos and high-engagement favorites.

| ID | Level | Priority | Test Scenario | Justification |
|----|-------|----------|---------------|---------------|
| 4.4-INT-015 | Integration | P1 | Grid contains mix: 30% new videos (no history), 70% known videos | Balance validation: novelty gets representation |
| 4.4-UNIT-012 | Unit | P1 | New videos with no history receive baseline weight 0.5 | Ensures new content visible but not dominant |
| 4.4-E2E-004 | E2E | P1 | Child sees both familiar videos and new content over 5 grid loads | User experience: balance perception over time |

**Coverage Summary:** 3 tests (1 unit, 1 integration, 1 E2E) - Validates novelty/favorites balance.

---

### AC7: Selection feels random to child despite weighting

**Test Strategy:** Integration tests for variance, E2E tests for user perception.

| ID | Level | Priority | Test Scenario | Justification |
|----|-------|----------|---------------|---------------|
| 4.4-INT-016 | Integration | P2 | Run selection 50 times, verify different orderings each time | Randomness validation: no deterministic patterns |
| 4.4-UNIT-013 | Unit | P2 | Use random.choices() not top-N deterministic selection | Algorithm design: weighted randomness preserved |
| 4.4-E2E-005 | E2E | P2 | Child refreshes grid 5 times, sees different videos each time | User perception: feels random despite weighting |

**Coverage Summary:** 3 tests (1 unit, 1 integration, 1 E2E) - UX polish: randomness perception validated.

---

### AC8: Algorithm maintains variety across multiple channels

**Test Strategy:** Unit tests for channel constraint logic, integration tests with real multi-channel data.

| ID | Level | Priority | Test Scenario | Justification |
|----|-------|----------|---------------|---------------|
| 4.4-UNIT-014 | Unit | P1 | Track channel counts during selection, set weight=0 when channel has 3 videos | Channel variety constraint algorithm |
| 4.4-UNIT-015 | Unit | P1 | Edge case: Single channel with 20 videos → all eligible | Constraint only applies when multiple channels exist |
| 4.4-INT-017 | Integration | P1 | Insert 20 videos from Channel A, 10 from Channel B → max 3 per channel in grid | Hard constraint validation with real data |
| 4.4-INT-018 | Integration | P1 | Run selection 50 times, verify no more than 3 videos per channel ever | Consistency: constraint always enforced |
| 4.4-E2E-006 | E2E | P1 | Child sees videos from 3+ different channels in single grid | User experience: channel variety visible |

**Coverage Summary:** 5 tests (2 unit, 2 integration, 1 E2E) - Prevents channel monotony, important for engagement.

---

### AC9: Edge case handling: all videos recently watched (select randomly)

**Test Strategy:** Integration tests for edge case detection and fallback behavior.

| ID | Level | Priority | Test Scenario | Justification |
|----|-------|----------|---------------|---------------|
| 4.4-UNIT-016 | Unit | P1 | Detect all weights <0.15 threshold → trigger random fallback | Edge case detection logic |
| 4.4-INT-019 | Integration | P1 | Mark all videos watched in last 1 hour → selection succeeds with random fallback | Prevents empty grid: critical edge case |
| 4.4-INT-020 | Integration | P1 | Edge case: No watch history (brand new) → equal weights (effectively random) | Cold start scenario: graceful handling |
| 4.4-UNIT-017 | Unit | P1 | Edge case: Channel has <3 videos → no constraint applied | Small channel edge case |

**Coverage Summary:** 4 tests (2 unit, 2 integration) - All edge cases have explicit fallback handling.

---

### AC10: Engagement data tracked in watch_history table (completed boolean, duration_watched_seconds)

**Test Strategy:** Integration tests for data integrity and TIER 1 safety (exclusion of manual_play and grace_play).

| ID | Level | Priority | Test Scenario | Justification |
|----|-------|----------|---------------|---------------|
| 4.4-INT-021 | Integration | P0 | Verify engagement query uses: AND manual_play = 0 AND grace_play = 0 | TIER 1 Safety: manual plays excluded (already covered by INT-001) |
| 4.4-INT-022 | Integration | P0 | Insert watch_history with completed=1 → increases engagement score | Data integrity: completed flag affects scoring |
| 4.4-INT-023 | Integration | P1 | Insert watch_history with duration_watched_seconds → used in calculations | Data tracking: duration available for future enhancements |
| 4.4-UNIT-018 | Unit | P0 | Database context manager used for all watch_history queries (TIER 2 Rule 7) | Code quality: consistent database access pattern |

**Coverage Summary:** 4 tests (1 unit, 3 integration) - Data integrity with TIER 1 focus on exclusions.

---

## TIER 1 Safety Tests Summary

**Critical Safety Rules Coverage:**

| Rule | Test IDs | Coverage Status |
|------|----------|-----------------|
| **Rule 1: Banned Videos Filtered** | 4.4-INT-024 | ✅ 100% - Covered |
| **Rule 2: Exclude manual_play & grace_play** | 4.4-INT-001, 4.4-INT-002 | ✅ 100% - Covered |
| **Rule 3: UTC Time for Recency** | 4.4-INT-006, 4.4-INT-008 | ✅ 100% - Covered |
| **Rule 6: SQL Placeholders** | 4.4-INT-013, 4.4-INT-025 | ✅ 100% - Covered |

**Additional TIER 1 Test:**

| ID | Level | Priority | Test Scenario | Justification |
|----|-------|----------|---------------|---------------|
| 4.4-INT-024 | Integration | P0 | Banned videos excluded from selection despite high engagement | TIER 1 Rule 1: Core safety - banned content never shown to child |
| 4.4-INT-025 | Integration | P0 | Code review: All SQL queries use placeholders (?, ?) not f-strings | TIER 1 Rule 6: SQL injection prevention |

---

## Performance Benchmarks (Task 11)

**Performance Test Strategy:** Use pytest-benchmark to validate algorithm scales to production dataset sizes.

| ID | Level | Priority | Test Scenario | Target |
|----|-------|----------|---------------|--------|
| 4.4-PERF-001 | Integration | P2 | Engagement calculation: 9 videos, 10K watch_history | <500ms |
| 4.4-PERF-002 | Integration | P2 | Weighted selection with constraints: 500 videos, 50K watch_history | <1000ms |
| 4.4-PERF-003 | Integration | P2 | Channel variety constraint overhead: 1000 videos, 50 channels | <100ms |
| 4.4-PERF-004 | Integration | P2 | Database index usage: verify query plan uses idx_watch_history_engagement | Optimization |

**Performance Notes:**
- Single-family deployment: moderate performance acceptable
- Targets based on Task 7 requirements
- If targets not met, document for future optimization story
- No caching in this story (per design decision)

---

## Grace Mode Special Handling

**Test Strategy:** Verify engagement logic bypassed in grace state (Story 4.3 compatibility).

| ID | Level | Priority | Test Scenario | Justification |
|----|-------|----------|---------------|---------------|
| 4.4-INT-026 | Integration | P0 | Grace mode (max_duration=300): engagement scoring NOT called | Story 4.3 compatibility: grace uses simple 5-min filter |
| 4.4-UNIT-019 | Unit | P0 | If max_duration == 300: return random.sample() immediately | Bypass logic correctness |

---

## Additional Unit Tests for Helper Functions

**Test Strategy:** Comprehensive unit coverage for all calculation helpers.

| ID | Level | Priority | Test Scenario | Justification |
|----|-------|----------|---------------|---------------|
| 4.4-UNIT-020 | Unit | P1 | Calculate hours since last watch with freezegun time-mocking | Time calculation accuracy |
| 4.4-UNIT-021 | Unit | P1 | Parse watch_history rows and extract unique watch days | Data transformation logic |
| 4.4-UNIT-022 | Unit | P1 | Logarithmic scaling: log(1 + 0) = 0, log(1 + 10) = 2.4 | Math function correctness |

---

## Test File Organization

**Backend Test Files:**
- `tests/backend/services/test_engagement_scoring.py` - TIER 1 safety tests (Task 8)
  - Tests: 4.4-INT-001, 4.4-INT-002, 4.4-INT-006, 4.4-INT-024, 4.4-INT-025
  - Mark with `@pytest.mark.tier1` decorator
  - Target: 100% coverage for engagement calculation functions

- `tests/backend/test_weighted_selection.py` - Integration tests (Task 9)
  - Tests: 4.4-INT-004, 4.4-INT-007, 4.4-INT-017, 4.4-INT-019, 4.4-INT-026
  - Use freezegun for time-mocking
  - Statistical tests (run selection N times)

- `tests/backend/services/test_engagement_helpers.py` - Unit tests (Task 10)
  - Tests: 4.4-UNIT-001 through 4.4-UNIT-022
  - Pure function testing, no database

- `tests/backend/benchmarks/test_engagement_performance.py` - Performance tests (Task 11)
  - Tests: 4.4-PERF-001 through 4.4-PERF-004
  - Use pytest-benchmark

**Frontend Test Files:**
- `frontend/src/admin/engagement-reset.test.js` - Admin UI tests
  - Button click behavior, confirmation dialog, API calls

**E2E Test Files:**
- `tests/e2e/engagement-selection.spec.js` - Playwright E2E tests
  - Tests: 4.4-E2E-001 through 4.4-E2E-006
  - Child video selection journey
  - Admin reset workflow

---

## Risk Coverage Matrix

**Story 4.4 Risk Profile Mapping:**

| Risk | Test Coverage | Mitigation |
|------|---------------|------------|
| **High engagement videos dominate, child sees same videos repeatedly** | 4.4-INT-004, 4.4-INT-007, 4.4-E2E-001 | Recency penalty + channel variety constraint |
| **New videos never selected (hidden by high-engagement favorites)** | 4.4-UNIT-010, 4.4-INT-009, 4.4-INT-015 | Minimum weight floor (0.05) + baseline weight (0.5) |
| **Banned videos slip through despite low engagement** | 4.4-INT-024 | TIER 1 safety test, existing filtering preserved |
| **Manual/grace plays inflate engagement unfairly** | 4.4-INT-001, 4.4-INT-002 | TIER 1 safety: exclusion in WHERE clause |
| **Timezone bugs in 24h recency calculation** | 4.4-INT-006, 4.4-INT-008 | TIER 1 UTC time enforcement |
| **Single channel dominates grid (20 Blippi videos)** | 4.4-INT-017, 4.4-INT-018, 4.4-E2E-006 | Hard constraint: max 3 per channel |
| **All videos recently watched → empty grid** | 4.4-INT-019 | Random fallback when all weights <0.15 |
| **Performance degrades with large watch history** | 4.4-PERF-001, 4.4-PERF-002 | Benchmark + index optimization |
| **Parent can't "start fresh" if algorithm feels stale** | 4.4-E2E-002, 4.4-E2E-003 | Admin reset functionality |

**Risk Mitigation Status:** All identified risks have explicit test coverage and mitigation strategies.

---

## Recommended Test Execution Order

### Phase 1: Safety-Critical (Fail Fast)
1. **TIER 1 Unit Tests** (4.4-UNIT-001 to 4.4-UNIT-022) - 5 minutes
2. **TIER 1 Integration Tests** (4.4-INT-001, 4.4-INT-002, 4.4-INT-006, 4.4-INT-024, 4.4-INT-025) - 10 minutes

### Phase 2: Core Functionality
3. **Engagement Calculation Tests** (4.4-INT-003, 4.4-INT-004, 4.4-INT-022) - 5 minutes
4. **Weighted Selection Tests** (4.4-INT-005, 4.4-INT-007, 4.4-INT-016) - 10 minutes
5. **Channel Variety Tests** (4.4-INT-017, 4.4-INT-018) - 5 minutes

### Phase 3: Edge Cases & Admin
6. **Edge Case Tests** (4.4-INT-019, 4.4-INT-020) - 5 minutes
7. **Admin Feature Tests** (4.4-INT-011 to 4.4-INT-014) - 5 minutes

### Phase 4: User Experience
8. **E2E Tests** (4.4-E2E-001 to 4.4-E2E-006) - 15 minutes

### Phase 5: Performance (Optional)
9. **Performance Benchmarks** (4.4-PERF-001 to 4.4-PERF-004) - 10 minutes

**Total Estimated Execution Time:** ~70 minutes (full suite)
**Critical Path Only:** ~20 minutes (Phase 1 + Phase 2 core tests)

---

## Coverage Gap Analysis

**Acceptance Criteria Coverage:**

| AC | Test Count | Status |
|----|------------|--------|
| AC1 (Engagement scoring) | 8 | ✅ Comprehensive |
| AC2 (Weighted selection) | 5 | ✅ Comprehensive |
| AC3 (Recency penalty) | 6 | ✅ Comprehensive |
| AC4 (Minimum weight floor) | 4 | ✅ Comprehensive |
| AC5 (Admin reset) | 6 | ✅ Comprehensive |
| AC6 (Novelty balance) | 3 | ✅ Adequate |
| AC7 (Feels random) | 3 | ✅ Adequate |
| AC8 (Channel variety) | 5 | ✅ Comprehensive |
| AC9 (Edge cases) | 4 | ✅ Comprehensive |
| AC10 (Data tracking) | 4 | ✅ Comprehensive |

**Coverage Gaps Identified:** None - All ACs have appropriate test coverage.

**Duplicate Coverage Check:**
- ✅ No duplicate coverage across levels (each test has unique justification)
- ✅ Critical paths have defense-in-depth (unit + integration + E2E where appropriate)
- ✅ TIER 1 safety tests focused on integration level (most appropriate)

---

## Test Design Quality Checklist

- [x] Every AC has test coverage
- [x] Test levels are appropriate (shift-left applied)
- [x] No duplicate coverage across levels without justification
- [x] Priorities align with business risk (TIER 1 = P0)
- [x] Test IDs follow naming convention (4.4-{LEVEL}-{SEQ})
- [x] Scenarios are atomic and independent
- [x] TIER 1 safety rules have explicit tests
- [x] Edge cases have fallback behavior tests
- [x] Performance benchmarks included per requirements
- [x] Risk coverage matrix complete

---

## Key Test Design Principles Applied

1. **Shift Left:** Favor unit tests for pure logic (51% unit tests)
2. **Risk-Based:** TIER 1 safety rules are P0 priority (9 tests)
3. **Efficient Coverage:** Each test validates unique aspect, no duplication
4. **Maintainability:** Clear justifications for future test maintenance
5. **Fast Feedback:** Unit tests run first, E2E tests last
6. **Defense in Depth:** Critical paths covered at multiple levels
7. **Edge Case Focus:** All AC9 edge cases have explicit tests
8. **Performance Aware:** Benchmarks included per Task 11

---

## Notes for Implementation

**Testing Tools:**
- pytest with fixtures from `tests/backend/conftest.py`
- freezegun for UTC time-mocking: `@freeze_time("2024-01-15 14:30:00")`
- pytest-benchmark for performance tests
- `@pytest.mark.tier1` decorator for safety tests
- Vitest + happy-dom for frontend tests
- Playwright for E2E tests

**Story 4.3 Compatibility:**
- Grace mode must bypass engagement logic (tests 4.4-INT-026, 4.4-UNIT-019)
- Existing filtering pipeline preserved (banned, available, duration)
- Frontend polling continues unchanged

**Data Setup for Tests:**
- Use in-memory SQLite database (from conftest.py fixtures)
- Seed watch_history with varying engagement patterns
- Include edge cases: no history, all recent, single channel, banned videos
- Use freezegun to control current time for recency tests

---

## YAML Gate Block for Quality Gate Integration

```yaml
test_design_4_4:
  date: '2025-11-03'
  designer: 'Quinn (Test Architect)'

  scenarios_total: 43

  by_level:
    unit: 22
    integration: 21
    e2e: 6

  by_priority:
    p0: 25
    p1: 12
    p2: 6

  tier1_safety_tests: 9
  tier1_coverage_target: '100%'

  performance_benchmarks: 4
  performance_targets:
    engagement_calculation: '<500ms'
    weighted_selection: '<1000ms'
    channel_constraint_overhead: '<100ms'

  coverage_gaps: []

  estimated_execution_time:
    full_suite: '70 minutes'
    critical_path: '20 minutes'

  risk_coverage:
    high_engagement_domination: 'Mitigated by recency penalty + variety tests'
    new_videos_hidden: 'Mitigated by minimum weight floor tests'
    banned_videos_slip: 'Mitigated by TIER 1 safety test 4.4-INT-024'
    manual_grace_inflation: 'Mitigated by TIER 1 exclusion tests'
    timezone_bugs: 'Mitigated by UTC enforcement tests'
    channel_domination: 'Mitigated by hard constraint tests'
    empty_grid_edge_case: 'Mitigated by random fallback tests'
    performance_degradation: 'Mitigated by benchmarks'
    stale_algorithm: 'Mitigated by admin reset tests'

  story_4_3_compatibility:
    grace_mode_bypass: 'Tested by 4.4-INT-026, 4.4-UNIT-019'
    existing_filters_preserved: 'Verified by 4.4-INT-024'
```

---

**Test Design Document Approved By:** Quinn (Test Architect)
**Date:** 2025-11-03
**Version:** 1.0
**Status:** Ready for Implementation
